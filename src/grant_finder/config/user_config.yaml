# User Configuration for Grant Finder Crew

# Company context directory configuration
company_context:
  directory: "C:/data/IA_company_context"

# Funding sources configuration
funding_sources:
  file_path: "C:/data/funding_sources/grant_funding_sources.csv"

# LLM Configuration
llm:
  # Can be "openai" or "bitnet"
  model_type: "bitnet"
  
  # OpenAI specific settings
  openai:
    model_name: "gpt-3.5-turbo-0125"
    temperature: 0.0
    request_timeout: 180
    max_tokens: 500
    max_retries: 3
    concurrency_limit: 2
    backoff_factor: 2
    min_delay: 1
  
  # BitNet specific settings
  bitnet:
    cli_path: "C:/code/Dynamo/shared_codebases/BitNet/build/bin/Release/llama-cli.exe"
    model_path: "C:/code/Dynamo/models/bitnet_b1_58-large/ggml-model-i2_s.gguf"
    model_size: "0.7B"
    quantization: "i2_s"
    kernel_type: "i2_s"
    threads: 4
    ctx_size: 2048
    temperature: 0.0
    n_predict: 128
    n_prompt: 512
    quant_embd: false
    use_pretuned: false

# Optional Configurations
output:
  format: "markdown"
  save_to_file: true
  output_directory: "C:/data/grant_finder_output"

logging:
  level: "INFO"
  file: "logs/grant_finder.log"

embeddings:
  provider: "openai"  # openai or "gptj". "bitnet does not have embeddings"
  save_path: "C:/data/IA_company_context/embeddings"  # Directory to save embeddings with provider info
  openai:
    model: "text-embedding-3-small"
    dimension: 1536
  bitnet:
    dimension: 1536
    batch_size: 32
  gptj:
    model_path: "C:/code/Dynamo/models/gptj/gptj-6b-ggml-q4.bin"
    tokenizer_path: "C:/code/Dynamo/models/gptj/tokenizer"
    dimension: 4096
    batch_size: 32